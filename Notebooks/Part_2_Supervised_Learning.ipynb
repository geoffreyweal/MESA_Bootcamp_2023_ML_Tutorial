{"cells":[{"cell_type":"markdown","metadata":{"id":"aqS5FDkJShr3"},"source":["# **Part 2: Supervised Learning: Classification**\n","\n","In **Supervised Learning**, we have a dataset consisting of both features and labels.\n","The task is to construct an estimator which is able to predict the label of an object\n","given the set of features. A relatively simple example is predicting the species of\n","Iris' given a set of measurements of its flower. Some more complicated examples are:\n","\n","- Given a multicolor image of an object through a telescope, determine\n","  whether that object is a star, a quasar, or a galaxy.\n","- Given a photograph of a person, identify the person in the photo.\n","- Given a list of movies a person has watched and their personal rating\n","  of the movie, recommend a list of movies they would like\n","  (So-called *recommender systems*: a famous example is the [Netflix Prize](http://en.wikipedia.org/wiki/Netflix_prize)).\n","\n","What these tasks have in common is that there is one or more unknown\n","quantities associated with the object which needs to be determined from other\n","observed quantities.\n","\n","Supervised learning is further broken down into two categories, **classification** and **regression**.\n","* In **classification**, the label is discrete, while in regression, the label is continuous. For example,\n","in astronomy, the task of determining whether an object is a star, a galaxy, or a quasar is a\n","classification problem: the label is from three distinct categories.\n","* On the other hand, we might wish to estimate the age of an object based on such observations: this would be a **regression** problem, because the label (age) is a continuous quantity.\n","This this worksheet, we will focus on **classification** problems.\n","\n","References: https://www.ibm.com/topics/supervised-learning\n","\n","## **Setting up our Notebook**\n","\n","To begin, we need to setup some python programs and download some files from Github. Run the code below by  **clicking the <img src=\"https://github.com/GardenGroupUO/Computational_Silver_Nanoparticle_Exercise_Data/blob/main/Images/stop_images/playsvg.png?raw=true\" alt=\"drawing\" width=\"28\"/> button below to load our prerequisite files**.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6EGU5shvShr5"},"outputs":[],"source":["# Numpy, Pandas and Scikit-Learn modules for Machine Learning Exercise\n","import numpy as np\n","import pandas as pd\n","from sklearn import datasets\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","# Pylab and Matplotlib for plotting\n","import pylab as pl\n","import matplotlib.pyplot as plt\n","from   matplotlib.lines import Line2D\n","from   matplotlib.colors import ListedColormap\n","%matplotlib inline\n","plt.style.use('seaborn')\n","\n","# Create color maps for 3-class classification problem, as with iris\n","cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n","cmap_bold = ListedColormap(['#FF0000', '#00A550', '#0000FF'])\n","\n","# Download and install packages that will be helpful for this section\n","%pip install -q ipywidgets\n","!apt-get -qq install subversion\n","!svn checkout https://github.com/geoffreyweal/MESA_Bootcamp_2023_ML_Tutorial/trunk/Notebooks/figure_code\n","\n","# Clear the output just for this cell cause there is a lot going on and doesnt help us.\n","# Comment this out if there is a problem when loading the programs and packages above\n","from IPython.display import clear_output\n","clear_output()"]},{"cell_type":"markdown","source":["When you click the <img src=\"https://github.com/GardenGroupUO/Computational_Silver_Nanoparticle_Exercise_Data/blob/main/Images/stop_images/playsvg.png?raw=true\" alt=\"drawing\" width=\"28\"/> button, it will be replaced with a <img src=\"https://github.com/GardenGroupUO/Computational_Silver_Nanoparticle_Exercise_Data/blob/main/Images/stop_images/stopsvg.gif?raw=true\" alt=\"drawing\" width=\"28\"/> icon.\n","\n","When the files have been successfully loaded, you will see the <img src=\"https://github.com/GardenGroupUO/Computational_Silver_Nanoparticle_Exercise_Data/blob/main/Images/stop_images/stopsvg.gif?raw=true\" alt=\"drawing\" width=\"28\"/> icon turn back into the <img src=\"https://github.com/GardenGroupUO/Computational_Silver_Nanoparticle_Exercise_Data/blob/main/Images/stop_images/playsvg.png?raw=true\" alt=\"drawing\" width=\"28\"/> button, and a <font color=\"green\" size=\"4\">&check;</font>tick symbol will appear next to the <img src=\"https://github.com/GardenGroupUO/Computational_Silver_Nanoparticle_Exercise_Data/blob/main/Images/stop_images/playsvg.png?raw=true\" alt=\"drawing\" width=\"28\"/> button. The <font color=\"green\" size=\"4\">&check;</font>tick symbol means that Google Colab was successfully able to run the code. Google Colab will tell you more information if it encounters an issue."],"metadata":{"id":"2FKGJcsukjlj"}},{"cell_type":"markdown","metadata":{"id":"cG6qFKHrShr6"},"source":["## **Troubleshooting**\n","\n","If you have any problems running this notebook, these suggestions may help.\n","\n","### **What to do if there is a problem running code:**\n","\n","Easiest thing to do if the code is not working as expected is to.\n","\n","On Google Colab:\n","1. Click ``Runtime`` > ``Disconnect and delete runtime``\n","2. A message will appear that will say ``Disconnect and delete runtime\n","Are you sure that you want to reset this runtime? The state of this runtime, including all local variables and files, will be lost``. Click the ``Yes`` button.\n","3. Repeat all the code you had run, or go ``Runtime`` > ``Run all`` to run all the code in sequence.\n","\n","On Visual Studio:\n","1. Click the ``Restart`` button at the top of Visual Studio,\n","2. Repeat all the code you had run, or click the ``Run All`` button at the top of Visual Studio.\n","\n","### **Can't I just load and run everything at once**\n","\n","You can run these Google Colab notebooks in full from start to end. To do this, at the top of the notebook click `Runtime -> Run all`. This will run every code box in the notebook. However, **this may take quite some time and is not recommended**.\n","\n","### **Help, I ran the code by accident!**\n","\n","If you want to stop code running at any time, you can press the <img src=\"https://github.com/GardenGroupUO/Computational_Silver_Nanoparticle_Exercise_Data/blob/main/Images/stop_images/stopsvg.gif?raw=true\" alt=\"drawing\" width=\"28\"/> icon at any time to stop the notebook from running the notebook's code.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"dCrsb4mkShr7"},"source":["## **Using the k Nearest Neighbours (kNN) ML algorithm to Predict Species of Iris'**\n","\n","The k nearest neighbors (kNN) algorithm is one of the simplest machine learning strategies. This algorithm works by making a decision based on the results of the k nearest neighbours, and giving a prediction based on the majority of what those points are. The algorithm works by:\n","\n","1. Give the parameters for a test sample you would like to get a prediction for.\n","2. Determine the k samples from the training set that have the most similar parameters to your sample.\n","3. Of those k most similar training samples, our prediction is the most common type.\n","\n","Let's try it out on our Iris classification problem. To begin, we will load the Iris data, create the kNN object that will perform the k-nearest neighbours ML algorithm, and get ``knn`` to fit our Iris data:\n","\n","### **Inspecting and Visualising the Iris Data**\n","\n","To begin, lets load the Iris data from Scikit-learn and look at what it contains."]},{"cell_type":"code","source":["# Load our Iris data from Scikit-learn.\n","iris = datasets.load_iris()\n","print(iris.keys())"],"metadata":{"id":"8kyI6ROrqGjh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The Iris dataset contains two components we will focus on, the ``data``, and the ``target``.\n","\n","The rows of the ``data`` and ``target`` lists give the corresponding sepal and petal information for each Iris that were sampled.\n","\n","The ``data`` contains an array with four columns. These columns describe the sepal length, sepal width, petal length, and petal width, respectively:"],"metadata":{"id":"Z05YBLZos4AO"}},{"cell_type":"code","source":["df = pd.DataFrame(iris['data'], columns=iris['feature_names'], index=range(1,len(iris['data'])+1))\n","display(df)"],"metadata":{"id":"4SJCAlGgs3fr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The ``target`` contains an array containing either the numbers:\n","* 0: Indicating the Iris is a Setosa,\n","* 1: Indicating the Iris is a Versicolour,\n","* 2: Indicating the Iris is a Virginica."],"metadata":{"id":"YN1l7WQ-tpi0"}},{"cell_type":"code","source":["corresponding_species = [iris['target_names'][target] for target in iris['target']]\n","df = pd.DataFrame({'target': iris['target'], 'Corresponding Species': corresponding_species}, index=range(1,len(iris['data'])+1))\n","display(df)"],"metadata":{"id":"0WZPebEJub6W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Lets take a look at the data visually. However, we have 4 pieces of data, the sepal length, sepal width, petal length, and petal width (Side note: this means our feature space has 4 dimensions). To begin, lets just focus on the sepal length and sepal width."],"metadata":{"id":"IkWgfO8ahxxn"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"_kJkkH8ehvhS"},"outputs":[],"source":["# Make a figure to show the data points for the sepal lengths and widths.\n","pl.figure()\n","\n","# Get our Iris data. Here, X_1 and y_1 will be used as our training data, where:\n","# * X_1 are our feature vectors\n","# * y_1 indicates if our Iris' flower is a setosa, versicolor, or virginica species\n","X_1 = iris.data[:, :2] # We only take the first two features (the sepal length and width).\n","y_1 = iris.target\n","sepal_length_limits  = (4.0, 8.0)\n","sepal_width_limits   = (1.9, 4.5)\n","\n","# Plot our sepal lengths and widths.\n","pl.scatter(X_1[:, 0], X_1[:, 1], c=y_1, cmap=cmap_bold)\n","pl.xlabel('sepal length (cm)')\n","pl.ylabel('sepal width (cm)')\n","pl.axis('tight')\n","pl.xlim(sepal_length_limits)\n","pl.ylim(sepal_width_limits)\n","\n","# Give the legend details.\n","legend_elements = [Line2D([0], [0], marker='o', color=cmap_bold(0), label='Setosa',      linewidth=0),\n","                   Line2D([0], [0], marker='o', color=cmap_bold(1), label='Versicolour', linewidth=0),\n","                   Line2D([0], [0], marker='o', color=cmap_bold(2), label='Virginica',   linewidth=0)]\n","pl.legend(handles=legend_elements,frameon=True)\n","pl.show()"]},{"cell_type":"markdown","source":["### **Making Iris Predictions using the kNN algorithm**\n","\n","We will now use a kNN model to predict the type of Iris species we have given Iris data. For our first example, we will only fit our sepal data (the sepal length and width). Here, we will set up a kNN model in python, and train our kNN model on our Iris data."],"metadata":{"id":"Z8ak-iFwugXY"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"K3incHrPShr7"},"outputs":[],"source":["# Get our Iris data. Here, X_1 and y_1 will be used as our training data, where:\n","# * X_1 are our feature vectors\n","# * y_1 indicates if our Iris' flower is a setosa, versicolor, or virginica species\n","X_1 = iris.data[:, :2]  # We only take the first two features (the sepal length and width).\n","y_1 = iris.target\n","\n","# Create the model in python.\n","n_neighbors_1 = 3\n","knn_1 = KNeighborsClassifier(n_neighbors=n_neighbors_1,metric='minkowski',p=2)\n","\n","# Train our kNN model on our Iris' data.\n","knn_1.fit(X_1, y_1)"]},{"cell_type":"markdown","metadata":{"id":"iu_XwKLiShr8"},"source":["We can now make a plot that shows what our kNN model predicts for different values of sepal length and width (our feature vectors)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HpwXnkBoShr8"},"outputs":[],"source":["# Create a meshgrid showing what our knn model predicts for all sepal lengths\n","# and widths between our limits.\n","sepal_length_limits  = (4.0, 8.0)\n","sepal_width_limits   = (1.9, 4.5)\n","sepal_lengths        = np.linspace(sepal_length_limits[0], sepal_length_limits[1], 100)\n","sepal_widths         = np.linspace(sepal_width_limits[0], sepal_width_limits[1], 100)\n","xx_1, yy_1           = np.meshgrid(sepal_lengths, sepal_widths)\n","\n","# Make a prediction of the results for the knn machine learning model for\n","# every sepal length between 4.0 cm to 8.0 cm, and every sepal width between\n","# 2.0 cm and 4.5 cm.\n","Z_1 = knn_1.predict(np.c_[xx_1.ravel(), yy_1.ravel()])\n","\n","# Convert our results into a meshgrid corresponding to xx_1 and yy_1 for all\n","# sepal lengths and widths between our limits.\n","Z_1 = Z_1.reshape(xx_1.shape)\n","\n","# Make a figure that shows the predictions of our knn model.\n","pl.figure()\n","pl.pcolormesh(xx_1, yy_1, Z_1, cmap=cmap_light)\n","\n","# Plot also our sepal training points.\n","pl.scatter(X_1[:, 0], X_1[:, 1], c=y_1, cmap=cmap_bold)\n","pl.xlabel('sepal length (cm)')\n","pl.ylabel('sepal width (cm)')\n","pl.axis('tight')\n","pl.xlim(sepal_length_limits)\n","pl.ylim(sepal_width_limits)\n","\n","# Give the legend details.\n","legend_elements = [Line2D([0], [0], marker='o', color=cmap_bold(0), label='Setosa',      linewidth=0),\n","                   Line2D([0], [0], marker='o', color=cmap_bold(1), label='Versicolour', linewidth=0),\n","                   Line2D([0], [0], marker='o', color=cmap_bold(2), label='Virginica',   linewidth=0)]\n","pl.legend(handles=legend_elements,frameon=True)\n","pl.show()"]},{"cell_type":"markdown","metadata":{"id":"SeFF4gw-Shr8"},"source":["For example, if we look at a iris with a sepal length of 5.5 cm and a sepal width of 3.0 cm, we see a green section of our figure. This would indicate our kNN model would predict an iris with this sepal width and length to be a versicolour species."]},{"cell_type":"markdown","metadata":{"id":"x2fct4ADShr9"},"source":["We can look at how the algorithm is making preductions by using the interactive plot below."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zwQL_JnkShr9"},"outputs":[],"source":["# Create interactive figure, containing lines for the k neighest neighbours about point i.\n","from figure_code import visualise_knn\n","visualise_knn(sepal_length_limits, sepal_width_limits, n_neighbors_1, 'definite', X_1, y_1, Z_1, xx_1, yy_1, cmap_light, cmap_bold, knn_1)"]},{"cell_type":"markdown","source":["**Use the sliders in the above plot to determine the prediction for different sepal lengths and widths and answer the following questions**.\n","\n","1. How many setosa, versicolour, and virginica nearest neighbours do we have for a sepal length of ~5.8 cm and a sepal width of ~3.4 cm?\n","2. What is our species prediction for this iris with a sepal length of ~5.8 cm and a sepal width of ~3.4 cm?\n","3. Repeat this exercise for an iris with a sepal length of ~5.6 cm and a sepal width of ~3.4 cm?\n","\n","Note: There is an weird area of this figure (sepal length of 6.25 cm and a sepal width of 3.18 cm) where versicolour is predicted, but there seems to be more blue point than green around this area. This is because there are more green points, they are just hidden beneath blue points with the same sepal length and sepal widths (This data contains overlapping flowers with similar or same sepal widths and lengths, but of different or same species)."],"metadata":{"id":"SCjK942UkeRQ"}},{"cell_type":"markdown","metadata":{"id":"1iN9all4Shr9"},"source":["### **Predicting the Probability of Iris species using the kNN algorithm**\n","\n","The version of the kNN model we have used above has been set to give a definite prediction for a Iris with a given sepal width and length. However, maybe we dont want our model to give a definite answer but rather a probabilistic prediction of what our Iris flower is?\n","\n","Lets try this below. NOTE: For this plot, the colours mean:\n","\n","* <font color=\"FF0000\" size=\"\">Red</font> region: Likely Setosa\n","* <font color=\"E0B91D\" size=\"\">Yellow</font> region: Either Setosa or Versicolour\n","* <font color=\"1AAA1A\" size=\"\">Green</font> region: Likely Versicolour\n","* <font color=\"#0FA3B1\" size=\"\">Aqua-marine</font> region: Either Versicolour or Virginica\n","* <font color=\"0000FF\" size=\"\">Blue</font> region: Likely Virginica\n","* <font color=\"F99EAD\" size=\"\">Pink</font> region: Either Versicolour or Virginica\n","* White region: Equally likely Setosa, Versicolour, or Virginica"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FvvEc9V6Shr-"},"outputs":[],"source":["# To begin, we will get our kNN model to give us predictions of what type of Iris species we have.\n","Z_1 = knn_1.predict_proba(np.c_[xx_1.ravel(), yy_1.ravel()])\n","\n","# Put the result into a color plot\n","Z_1 = Z_1.reshape(list(xx_1.shape)+[3])\n","\n","# To make it a bit easier to see what is going on, we will lighten the the regions of colour a bit.\n","from figure_code import lighten_rgb_color\n","for i1 in range(len(Z_1)):\n","    for i2 in range(len(Z_1[i1])):\n","        Z_1[i1][i2] = lighten_rgb_color(Z_1[i1][i2], 0.65)\n","\n","# Now lets visualise the data like we did before, but now for probabilities.\n","visualise_knn(sepal_length_limits, sepal_width_limits, n_neighbors_1, 'probabilistic', X_1, y_1, Z_1, xx_1, yy_1, cmap_light, cmap_bold, knn_1)"]},{"cell_type":"markdown","metadata":{"id":"ZR4JWqe9Shr-"},"source":["**Use the sliders in the above plot to determine the probabilistic predictions for different sepal lengths and widths and answer the following questions**.\n","\n","1. How many setosa, versicolour, and virginica nearest neighbours do we have for a sepal length of ~5.8 cm and a sepal width of ~3.4 cm?\n","2. What is our species prediction for this iris with a sepal length of ~5.8 cm and a sepal width of ~3.4 cm?\n","3. Repeat this exercise for an iris with a sepal length of ~5.6 cm and a sepal width of ~3.4 cm?\n","\n","--------\n","\n","In ML models, a common method for improving the predictive ability of the model is to tune the settings of the model. For the k-Nearest Neighbour algorithm, this is done by changing the number of nearest neighbours that are analysed.\n","\n","Currently the number of nearest neighbours (``n_neighbors``) that are analysed is 3. We could try a range of these ``n_neighbors`` and see what happens. This may be important, in paricular because some of our versicolour and virginic datapoints have exactly the same sepal widths and lengths:\n","\n","Note: when changing the ``prediction_type``, it may take a few second to load the definite/probabilistic plots."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tX-OxqFUShr-"},"outputs":[],"source":["# Reload our Iris data, and only read in the sepal width and length from the dataset.\n","iris = datasets.load_iris()\n","X = iris.data[:, :2] # We only take the first two features (the sepal length and width).\n","y = iris.target\n","\n","# Show figure that indicates what type of iris is predicted by the knn algorithm for different values of n_neighbors.\n","from figure_code import visualise_multi_knn\n","visualise_multi_knn(sepal_length_limits, sepal_width_limits, X, y, cmap_light, cmap_bold)"]},{"cell_type":"markdown","metadata":{"id":"RORFR5a6Shr-"},"source":["These plots are great to see how our kNN model decides what type of iris type we have based on sepal length and width, but it's still a bit hard to figure out which value of ``n_neighbors`` to choose.\n","\n","What we could also do is to test how well the kNN algorithm works using a **training and testing set of data**. Here, we randomly split our data into 70 % training data and 30 % testing data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vIBHrft1Shr-"},"outputs":[],"source":["from sklearn import datasets\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import train_test_split\n","\n","# Get our Iris data.\n","iris = datasets.load_iris()\n","X = iris.data[:, :2]  # We only take the first two features (the sepal length and width).\n","y = iris.target\n","\n","# Split the data into training and testing data.\n","X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, train_size=0.7, random_state=42)\n","\n","# Testing KNN algorithm for several values of ``n_neighbors``.\n","training_accuracy = []\n","test_accuracy = []\n","neighbors_settings = tuple(range(1, 10))\n","for n_neighbors in neighbors_settings:\n","    # Build the model.\n","    clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n","    clf.fit(X_train, y_train)\n","    # Record training set accuracy.\n","    training_accuracy.append(clf.score(X_train, y_train))\n","    # Record generalization accuracy.\n","    test_accuracy.append(clf.score(X_test, y_test))\n","\n","# Plot results for several values of ``n_neighbors``.\n","pl.plot(neighbors_settings, training_accuracy, '-', label=\"training accuracy\")\n","pl.plot(neighbors_settings, test_accuracy, 'r--', label=\"test accuracy\")\n","pl.ylabel(\"Accuracy\")\n","pl.xlabel(\"n_neighbors\")\n","pl.ylim((0.5,1.0))\n","pl.legend()\n","pl.show()"]},{"cell_type":"markdown","metadata":{"id":"36rmHSczShr_"},"source":["Now, we can see maybe ``n_neighbors=6`` may be the best based on the test data."]},{"cell_type":"markdown","metadata":{"id":"pneiekbdShr_"},"source":["## **Using More than 2 Features in our Feature Space**\n","\n","So far we have only used the sepal data, but we should also use the petal width and length. Lets repeat the above testing proceedure, where the feature vector includes the sepal length and width, as well as the petal length and width.\n","\n","Again, we will split our data into 70 % training set and 30 % test set."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9L40SoHgShr_"},"outputs":[],"source":["from sklearn import datasets\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import train_test_split\n","\n","# Get our Iris data.\n","iris = datasets.load_iris()\n","X = iris.data  # We will now use all the Iris data for this exercise. This was originally \"X_1 = iris.data[:, :2]\"\n","y = iris.target\n","\n","# Split the data into training and testing data.\n","X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, train_size=0.7, random_state=42)\n","\n","# Testing KNN algorithm for several values of ``n_neighbors``.\n","training_accuracy = []\n","test_accuracy = []\n","for n_neighbors in range(1, 10):\n","    # Build the model.\n","    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n","    knn.fit(X_train, y_train)\n","    # Record training set accuracy.\n","    training_accuracy.append(knn.score(X_train, y_train))\n","    # Record generalization accuracy.\n","    test_accuracy.append(knn.score(X_test, y_test))\n","\n","# Plot results for several values of ``n_neighbors``.\n","pl.plot(neighbors_settings, training_accuracy, '-', label=\"training accuracy\")\n","pl.plot(neighbors_settings, test_accuracy, 'r--', label=\"test accuracy\")\n","pl.ylabel(\"Accuracy\")\n","pl.xlabel(\"n_neighbors\")\n","pl.ylim((0.5,1.0))\n","pl.legend()\n","pl.show()"]},{"cell_type":"markdown","metadata":{"id":"Liz6lAi9Shr_"},"source":["We can see why adding the petal length and width will improve the accuracy of our model by looking at the data.\n","\n","Because it is hard to plot four feature vectors (sepal length, width width, petal length, and petal width), lets just plot the sepal length, width width, and the petal length on a 3D scatter plot.\n","\n","We can see that even just including the petal width significantly helps to distinguish between versicolor and virginica iris'."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5x2qT6UZShsA"},"outputs":[],"source":["# We will plot the sepal length, sepal width, and petal width in a 3D scatterplot.\n","import plotly.express as px\n","df = px.data.iris()\n","fig = px.scatter_3d(df, x='sepal_length', y='sepal_width', z='petal_width', color='species', color_discrete_map={'setosa': '#FF0000', 'versicolor': '#00A550', 'virginica': '#0000FF'}, width=1200, height=900)\n","fig.show()"]},{"cell_type":"markdown","metadata":{"id":"vjep_BurShsA"},"source":["We can see that the accuracy of our kNN model is considerably better than before for any value of ``n_neighbours`` we choose by including more feature vectors (i.e. including petal width and length in our kNN model).\n","\n","Lets arbitrarily choose ``n_neighbours=5`` for the last exercise, but partially because ``n_neighbours=5`` does the best for preducting the testing set of data. Now lets make a prediction for a sample of an iris with:\n","* Sepal length: 3.6 cm\n","* Sepal width: 2.9 cm\n","* Petal length: 3.1 cm\n","* Petal width: 2.0 cm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9BxqWOU3ShsA"},"outputs":[],"source":["from sklearn import datasets\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","\n","# Get our Iris data.\n","iris = datasets.load_iris()\n","X = iris.data  # We only take the first two features (the sepal length and width).\n","y = iris.target\n","\n","# Splitting the data into training and testing data.\n","X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, train_size=0.7, random_state=69)\n","\n","# Initialise our kNN classification machine learning model.\n","knn = KNeighborsClassifier(n_neighbors=5)\n","\n","# Fit our kNN model with the Iris data .\n","knn.fit(X, y)\n","\n","# Make a probablistic prediction of the type of Iris species we have\n","# for a Iris with the following sepal length, sepal width, petal length,\n","# and petal width.\n","iris_input_values = [3.6, 2.9, 3.1, 2.0]\n","probabilities = knn.predict_proba([iris_input_values,])*100.0\n","\n","# Show the probabilities that are species is a setosa, versicolour,\n","# or virginica iris in a table\n","df = pd.DataFrame(probabilities)\n","df.columns = ['Setosa', 'Versicolour', 'Virginica']\n","df.index = ['Probabilities (%)']\n","display(df)"]},{"cell_type":"markdown","metadata":{"id":"baMuZ1evShsA"},"source":["We can see that for this set of input variables, our model indicates that our sample is likely to be a versicolour (80 %), but there is a slight change it is a virginica (20 %)."]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"orig_nbformat":4,"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}