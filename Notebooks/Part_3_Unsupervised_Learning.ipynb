{"cells":[{"cell_type":"markdown","metadata":{"id":"HAVJmqzmNg5e"},"source":["# **Part 3: Unsupervised Learning: Dimensionality Reduction**\n","\n","**Unsupervised Learning** addresses a different sort of problem. Unsupervised Learning is best used to finding similarities between the objects in our dataset. The data does not need to be labelled to be used in an unsupervised learning model. In a sense, you can think of unsupervised learning as a means of discovering labels from the data itself.\n","\n","Unsupervised learning comprises tasks such as **dimensionality reduction**, **clustering**, and\n","**density estimation**. For example, in the Iris data discussed previously, we can use unsupervised\n","methods to determine combinations of the measurements which best display the structure of the\n","data. As we'll see below, such a projection of the data can be used to visualize the\n","four-dimensional dataset in two dimensions. Some more involved unsupervised learning problems are:\n","\n","- given detailed observations of distant galaxies, determine which features or combinations of\n","  features best summarize the information.\n","- given a mixture of two sound sources (for example, a person talking over some music),\n","  separate the two (this is called the [blind source separation](http://en.wikipedia.org/wiki/Blind_signal_separation) problem).\n","- given a video, isolate a moving object and categorize in relation to other moving objects which have been seen.\n","\n","Sometimes the two may even be combined: e.g. Unsupervised learning can be used to simplify complex data, and then these features can be used within a supervised framework.\n","\n","References: https://www.ibm.com/topics/unsupervised-learning\n","\n","## **Setting up our Notebook**\n","\n","In this notebook, we will focus on using dimensionality reduction algorithms for maching a machine vision algorithm.\n","\n","Run the setup code below and lets get started!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xKPkqDLaNg5g"},"outputs":[],"source":["# Message to say that you will see things happening below here, this is expected\n","print('--------------------------------------------------------------------')\n","print('Programs are downloading and installing on Google computer (not your computer)')\n","print('You will see code appearing below, this is normal.')\n","print('Once everything has installed successfully, this code will vanish')\n","print('--------------------------------------------------------------------')\n","print()\n","\n","# Numpy and Pandas modules.\n","import numpy as np\n","import pandas as pd\n","\n","# Plotly and Matplotlib for plotting.\n","import plotly.express as px\n","import matplotlib.pyplot as plt\n","from matplotlib.colors import rgb2hex\n","%matplotlib inline\n","plt.style.use('seaborn')\n","\n","# Download and install packages that will be helpful for this section.\n","%pip install -q ipywidgets\n","!apt-get -qq install subversion\n","!svn checkout https://github.com/geoffreyweal/MESA_Bootcamp_2023_ML_Tutorial/trunk/Notebooks/figure_code\n","\n","# Clear the output just for this cell cause there is a lot going on and doesnt help us.\n","# Comment this out if there is a problem when loading the programs and packages above\n","from IPython.display import clear_output\n","clear_output()\n","print('Programs successfully installed on Google computer')"]},{"cell_type":"markdown","metadata":{"id":"P2T4ixJSNg5i"},"source":["## **Creating a Machine Vision Model for Numbers**\n","\n","### **Inspecting and Visualising the Numbers Data**\n","\n","For this exercise, we will create a machine learning model that can identify a number that has been written by a human."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LGDBHvVpNg5i"},"outputs":[],"source":["from sklearn import datasets\n","digits = datasets.load_digits()"]},{"cell_type":"markdown","metadata":{"id":"2r2FsG5xNg5i"},"source":["Let's plot some of the numbers that have been given in this dataset. The numbers in the dataset are represented by an 8x8 grid of pixels:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CeZ0Ipy8Ng5i"},"outputs":[],"source":["fig, axes = plt.subplots(10, 10, figsize=(8, 8))\n","fig.subplots_adjust(hspace=0.1, wspace=0.1)\n","\n","for i, ax in enumerate(axes.flat):\n","    ax.imshow(digits.images[i], cmap='binary', interpolation='nearest')\n","    ax.text(0.05, 0.05, str(digits.target[i]),\n","            transform=ax.transAxes, color='blue')\n","    ax.set_xticks([])\n","    ax.set_yticks([])"]},{"cell_type":"markdown","metadata":{"id":"IsZXAn9wNg5j"},"source":["We can see how the raw data naturally gives itself to pictorially describe the numbers by looking at the raw data for one of the numbers below:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LbLR96YRNg5j"},"outputs":[],"source":["# Choose an index from the images and targe list to show:\n","index = 10 # feel free to change this between 0 and 1796\n","\n","# The images themselves.\n","print('------------------------------------')\n","print('Data for setting pixels for the number image sampled')\n","print(digits.images[index])\n","\n","# The target label, what the numbers are.\n","print('------------------------------------')\n","print('Shows that each number that the image above is trying to describe')\n","print(digits.target[index])\n","print('------------------------------------')"]},{"cell_type":"markdown","metadata":{"id":"ItcWFGwPNg5j"},"source":["You can probably see that the 8x8 raw pixel data seems to give the shape of a zero.\n","\n","The code below shows that we have 1797 samples in our dataset, where each number is described with 64 pixels (8 pixels by 8 pixels). We therefore say that our feature space contains 64 dimensions, where each dimension is the shade (blackness) of each pixel in the image."]},{"cell_type":"code","source":["print(digits.images.shape)"],"metadata":{"id":"QlysdxtpEhZp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qdk-XFx5Ng5k"},"source":["### **Dimensionality Reduction using the Principle Component Analysis (PCA) algorithm**\n","\n","We'd like to visualize our points within the 64-dimensional parameter space, but it's difficult to plot points in 64 dimensions! Instead we'll reduce the dimensions to 2, using an unsupervised method called the Principle Component Analysis (PCA) algorithm.\n","\n","The PCA algorithm works by determining how to transform the data to maximise the variance between points in the dataset. See https://en.wikipedia.org/wiki/Principal_component_analysis for more information about the PCA algorithm.\n","\n","Lets try out the PCA algorithm on our digits data below:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aQD5SJyvLoSz"},"outputs":[],"source":["# Initialise the PCA model in python.\n","from sklearn.decomposition import PCA\n","pca = PCA(n_components=2)\n","\n","# Perform the PCA algorithm upon our dataset.\n","data_projected = pca.fit_transform(digits.data)\n","\n","# Plot the data that has been spreadout using the PCA.\n","plt.scatter(data_projected[:, 0], data_projected[:, 1], c=digits.target, edgecolor='none', alpha=0.5, cmap=plt.colormaps.get_cmap('nipy_spectral_r').resampled(10));\n","plt.colorbar(label='digit label', ticks=range(10))\n","plt.clim(-0.5, 9.5)\n","plt.xlabel(\"Principal Component 1\")\n","plt.ylabel(\"Principal Component 2\")\n","ax = plt.gca()\n","ax.set_aspect('equal', adjustable='box')\n","plt.show()"]},{"cell_type":"markdown","source":["We can see that our PCA model is doing a reasonable job at spreading out the data, and gives regions of the above plots where we would find each of our numbers."],"metadata":{"id":"ZjDrhNFtXHfZ"}},{"cell_type":"markdown","metadata":{"id":"G5kpNsvkNg5k"},"source":["### **Classification on Digits: Adding a Supervised-Learning Algorithm**\n","\n","Let's try a classification task on the digits. The first thing we'll want to do is split the digits into a training and testing sample. Here, we will split our data into 70% for training and 30% for testing (validation):"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"scFpPxevNg5l"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","# Split our dataset into a training set and a testing set.\n","Xtrain, Xtest, ytrain, ytest, indices_train, indices_test = train_test_split(data_projected, digits.target, range(len(digits.target)), train_size=0.7, random_state=69)\n","print('Number of data in the training set: '+str(Xtrain.shape[0]))\n","print('Number of data in the testing set:  '+str(Xtest.shape[0]))"]},{"cell_type":"markdown","metadata":{"id":"Ra343EB1NaZE"},"source":["We can now use the results from the PCA algorithm to train a supervised classification machine learning algorithm. Here, we will use the C-Support Vector Classification (SVC) algorithm. We won't go into what this machine learning algorithm is doing, just to say it is a commonly used supervised classification machine learning algorithm that works very well in many applications:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m5f26ck1NaZE"},"outputs":[],"source":["# Initialise the support vector classification algorithm in python.\n","# Will include KNN algorithm here to see that no big change has happened\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.svm import SVC\n","\n","#ml_algorithm = KNeighborsClassifier(n_neighbors=5)\n","ml_algorithm = SVC(C=100)\n","\n","# Train our dataset with the traning dataset that has been modified by the PCA algorithm.\n","ml_algorithm.fit(Xtrain, ytrain)\n","\n","# Make predictions for our testing dataset.\n","ypred = ml_algorithm.predict(Xtest)"]},{"cell_type":"markdown","metadata":{"id":"W9vkXpvMNaZE"},"source":["We can check our classification accuracy by comparing the true values of the test set to the predictions:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uRi1-k98NaZF"},"outputs":[],"source":["from sklearn.metrics import accuracy_score\n","\n","# Compare the results from our predictions with what the number actually is.\n","print('accuracy score: '+str(accuracy_score(ytest, ypred)))"]},{"cell_type":"markdown","metadata":{"id":"gf3WTflDNaZF"},"source":["This accuracy number is great, but it doesn't tell us **where** we've gone wrong (i.e. which predictions of numbers it is getting wrong).\n","\n","One nice way to do this is to use the *confusion matrix*. Below shows a confusion matrix with colours to guide where our ML model is working well and where is it getting \"confused\"."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qyjh1wlNNaZF"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","\n","# Version with colour\n","\n","# Showing the results of the confusion matrix with colours. The darker the colour, the greater the number.\n","labels = sorted(set(ytest.tolist() + ypred.tolist()))\n","cm = confusion_matrix(ytest, ypred, labels=labels)\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n","\n","disp.plot(cmap='Blues')\n","plt.grid(False)\n","plt.ylabel('Actual Number')\n","plt.xlabel('Predicted Number')\n","plt.yticks(range(10))\n","plt.xticks(range(10))\n","ax = plt.gca()\n","ax.xaxis.tick_top()\n","ax.xaxis.set_label_position('top')\n","plt.show()"]},{"cell_type":"code","source":["# @title <p> (Here is the code to show the confusion cell without colour if desired. It is hidden, but you can unhide the code by clicking on the black triangle symbol â–¶ to the left of this paragraph)</p>\n","# Version without colour\n","\n","\"\"\" # remove these three quote symbols to run this code\n","\n","# Create the confusion matrix between the PCA+SVC predictions and the actual results we expect.\n","confmat = (confusion_matrix(ytest, ypred))\n","\n","# Create a spreadsheet showing the results of the confusion matrix.\n","df = pd.DataFrame(data=confmat, columns=range(len(confmat)), index=range(len(confmat)))\n","overall_df = pd.DataFrame(\n","    df.values,\n","    pd.MultiIndex.from_product([['Actual Numbers'], df.index]),\n","    pd.MultiIndex.from_product([['Predicted Numbers'], df.columns])\n",")\n","overall_df.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\n","display(overall_df)\n","\n","# This will display the total number of samples in the train set that will be included in the confusion matrix.\n","#total = sum([sum(df[index]) for index in range(len(df))])\n","#print('Total number of testing set samples: '+str(total))\n","\n","\"\"\" # remove these three quote symbols to run this code\n","print()"],"metadata":{"cellView":"form","id":"Fg1rEfD9Gtvk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SohHcr8BNaZF"},"source":["As you can see below, it looks like our simple PCA+SVM machine learning algorithms are working ok.\n","\n","We can also take a look at some of the outputs along with their predicted labels.\n","* Successful predictions have been marked with <font color=\"green\">green</font>.\n","* Unsuccessful predictions have been marked with <font color=\"red\">red</font>."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N-9YLF4NNaZG"},"outputs":[],"source":["fig, axes = plt.subplots(10, 10, figsize=(8, 8))\n","fig.subplots_adjust(hspace=0.1, wspace=0.1)\n","\n","for i, ax in enumerate(axes.flat):\n","    ax.imshow(digits.images[indices_test[i]], cmap='binary')\n","    ax.text(0.05, 0.05, str(ypred[i]), transform=ax.transAxes,\n","            color='green' if (ytest[i] == ypred[i]) else 'red')\n","    ax.set_xticks([])\n","    ax.set_yticks([])\n","fig.show()"]},{"cell_type":"markdown","metadata":{"id":"QDn2Qj2kLoSz"},"source":["### **Changing the Dimensionality of your PCA Model**\n","\n","We can see that the PCA algorithm is able to separate the data pretty well into 2 dimensions. We could improve the separation by reducing the dimensionality of the feature vector into 3 dimensions rather than 2. Maybe this could improve our PCA+SVM ML model?\n","\n","To begin, lets look at the PCA data when given 3 dimensions by running the code below:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5n8FbNyHLoS0"},"outputs":[],"source":["# Initialise the PCA algorithm that will spread the data into 3 dimensions.\n","pca = PCA(n_components=3)\n","\n","# Perform the PCA algorithm upon our dataset.\n","data_projected = pca.fit_transform(digits.data)\n","\n","# Show the dataset that has been spread out with the PCA algorithm in 3 dimensions\n","# with a 3D scatterplot.\n","data = data_projected.tolist()\n","for index in range(len(data)):\n","    target = digits.target[index]\n","    data[index] = data[index] + [str(target)]\n","df = pd.DataFrame(data, columns=['Feature 1', 'Feature 2', 'Feature 3', 'number'])\n","cmap = plt.colormaps.get_cmap('nipy_spectral_r').resampled(10)\n","color_discrete_map = {str(target): rgb2hex(cmap(target)).upper() for target in range(0,10)}\n","fig = px.scatter_3d(df, x='Feature 1', y='Feature 2', z='Feature 3', color='number', color_discrete_map=color_discrete_map, width=1000, height=1000)\n","fig.show()"]},{"cell_type":"markdown","source":["Try training your ML model with different values of ``n_components`` for the PCA algorithm and see how well your accuracy improves.\n","\n","``n_components`` can be set between 1 and 64 (64 is the maximum number of feature vectors our data contains, where each image has 64 pixels)."],"metadata":{"id":"utdudh1dMDDd"}},{"cell_type":"code","source":["# Set up your PCA algorithm that will spread out your data in the number of dimensions you desire.\n","pca = PCA(n_components=1) # <== Change this number and see how the accuracy changes.\n","data_projected = pca.fit_transform(digits.data)\n","\n","# Separate your data into a training set (70 %) and a testing set (30 %).\n","Xtrain, Xtest, ytrain, ytest, indices_train, indices_test = train_test_split(data_projected, digits.target, range(len(digits.target)), train_size=0.7, random_state=69)\n","\n","# Initialise the support vector classification algorithm in python.\n","#ml_algorithm = KNeighborsClassifier(n_neighbors=5)\n","ml_algorithm = SVC(C=100)\n","\n","# Train our dataset with the traning dataset that has been modified by the PCA algorithm.\n","ml_algorithm.fit(Xtrain, ytrain)\n","\n","# Make predictions for our testing dataset.\n","ypred = ml_algorithm.predict(Xtest)\n","\n","# Compare the results from our predictions with what the number actually is.\n","print('Accuracy Score: '+str(accuracy_score(ytest, ypred)))\n","print()\n","\n","# --------------------------------------------------------------------------\n","# Create a spreadsheet showing the results of the confusion matrix.\n","overall_df = pd.DataFrame(\n","    df.values,\n","    pd.MultiIndex.from_product([['Actual Numbers'], df.index]),\n","    pd.MultiIndex.from_product([['Predicted Numbers'], df.columns])\n",")\n","overall_df.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\n","#display(overall_df) # If you want to see the confusion matrix without colour, uncomment this out.\n","# --------------------------------------------------------------------------\n","\n","# Showing the results of the confusion matrix with colours. The darker the colour, the greater the number.\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","labels = sorted(set(ytest.tolist() + ypred.tolist()))\n","cm = confusion_matrix(ytest, ypred, labels=labels)\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n","\n","disp.plot(cmap='Blues')\n","plt.grid(False)\n","plt.ylabel('Actual Number')\n","plt.xlabel('Predicted Number')\n","plt.yticks(range(10))\n","plt.xticks(range(10))\n","ax = plt.gca()\n","ax.xaxis.tick_top()\n","ax.xaxis.set_label_position('top')\n","plt.show()"],"metadata":{"id":"lyyP3hf0QrQr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can plot all the accuracy scores for all possible number of components, and used this to determine a good value for ``n_components``:"],"metadata":{"id":"dVAC7BxoUaiq"}},{"cell_type":"code","source":["# Set up lists for recording data.\n","all_n_components    = list(range(1,64+1))\n","all_accuracy_scores = []\n","\n","for n_components in all_n_components:\n","\n","  # Set up your PCA algorithm that will spread out your data in the number of dimensions you desire.\n","  pca = PCA(n_components=n_components)\n","  data_projected = pca.fit_transform(digits.data)\n","\n","  # Separate your data into a training set (70 %) and a testing set (30 %).\n","  Xtrain, Xtest, ytrain, ytest, indices_train, indices_test = train_test_split(data_projected, digits.target, range(len(digits.target)), train_size=0.7, random_state=69)\n","\n","  # Initialise the support vector classification algorithm in python.\n","  #ml_algorithm = KNeighborsClassifier(n_neighbors=5)\n","  ml_algorithm = SVC(C=100)\n","\n","  # Train our dataset with the traning dataset that has been modified by the PCA algorithm.\n","  ml_algorithm.fit(Xtrain, ytrain)\n","\n","  # Make predictions for our testing dataset.\n","  ypred = ml_algorithm.predict(Xtest)\n","\n","  # Compare the results from our predictions with what the number actually is.\n","  score = accuracy_score(ytest, ypred)\n","\n","  all_accuracy_scores.append(score)\n","\n","# Plot the acccuracy scores across all the possible n components\n","plt.plot(all_n_components, all_accuracy_scores, 'o--');\n","plt.ylim((-0.01,1.01))\n","plt.xlim((0,65))\n","plt.xticks([1]+list(range(5,65,5))+[64])\n","plt.xlabel(r'Possible $n$ components')\n","plt.ylabel('Accuracy Score')\n","plt.show()"],"metadata":{"id":"ZOyyLgldUa6N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Also have a look at the results your set for your numbers and see how they change as you change the dimensionality of the PCA algorithm"],"metadata":{"id":"MFfTB_V6njXE"}},{"cell_type":"code","source":["# Set up your PCA algorithm that will spread out your data in the number of dimensions you desire.\n","pca = PCA(n_components=14) # <== Change this number to the number of components you want to try\n","data_projected = pca.fit_transform(digits.data)\n","\n","# Separate your data into a training set (70 %) and a testing set (30 %).\n","Xtrain, Xtest, ytrain, ytest, indices_train, indices_test = train_test_split(data_projected, digits.target, range(len(digits.target)), train_size=0.7, random_state=69)\n","\n","# Initialise the support vector classification algorithm in python.\n","#ml_algorithm = KNeighborsClassifier(n_neighbors=5)\n","ml_algorithm = SVC(C=100)\n","\n","# Train our dataset with the traning dataset that has been modified by the PCA algorithm.\n","ml_algorithm.fit(Xtrain, ytrain)\n","\n","# Make predictions for our testing dataset.\n","ypred = ml_algorithm.predict(Xtest)\n","\n","# Show some of the prediction results from our ML model\n","fig, axes = plt.subplots(10, 10, figsize=(8, 8))\n","fig.subplots_adjust(hspace=0.1, wspace=0.1)\n","\n","for i, ax in enumerate(axes.flat):\n","    ax.imshow(digits.images[indices_test[i]], cmap='binary')\n","    ax.text(0.05, 0.05, str(ypred[i]),\n","            transform=ax.transAxes,\n","            color='green' if (ytest[i] == ypred[i]) else 'red')\n","    ax.set_xticks([])\n","    ax.set_yticks([])\n","fig.show()"],"metadata":{"id":"PM3RfW6MnXsA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Try out other Unsupervised ML algorithms**\n","\n","Often, it is desirable to try a bunch of different unsupervised (and supervised) ML algorithms to figure out which algorithms are best for your problem/application.\n","\n","Try out the following unsupervised algorithms and figure out which one will be the best classifying digits from looking at the plots."],"metadata":{"id":"e7KNt6NdfUg0"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z6LmS-feLoS0"},"outputs":[],"source":["# Get the different types of unsupervised machine learning models from Scikit-Learn.\n","from sklearn.decomposition import PCA\n","from sklearn.manifold import Isomap\n","from sklearn.manifold import TSNE\n","\n","# -----------------------------------------------------------------------------------------------\n","# Comment and uncomment out the following unsupervised ML models to try them out.\n","unsupervised_model = PCA(n_components=2) # Feel free to change n_components, but try n_components=2 first.\n","#unsupervised_model = Isomap(n_components=2) # Feel free to change n_components, but try n_components=2 first.\n","#unsupervised_model = TSNE(n_components=2,random_state=42) # We dont need to set ``random_state`` to 42, this will just allow us to compare results between people for teaching purposes.\n","# -----------------------------------------------------------------------------------------------\n","\n","# Use our unsupervised model to spread out our dataset in 2 dimensions.\n","reduced_dimension_data = unsupervised_model.fit_transform(digits.data)\n","\n","# Assign colours to each number we want our algorithm to recognise.\n","cmap = plt.colormaps.get_cmap('nipy_spectral').resampled(10)\n","\n","# Plot the data in 2 dimensions.\n","plt.scatter(reduced_dimension_data[:, 0], reduced_dimension_data[:, 1], c=digits.target, edgecolor='none', alpha=0.5, cmap=plt.colormaps.get_cmap('nipy_spectral_r').resampled(10));\n","plt.colorbar(label='digit label', ticks=range(10))\n","plt.clim(-0.5, 9.5)\n","plt.xlabel(\"Feature 1\")\n","plt.ylabel(\"Feature 2\")\n","ax = plt.gca()\n","ax.set_aspect('equal', adjustable='box')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"9_wCFSFILoS0"},"source":["Confirm how well you think each unsupervised ML algorithm is working by running the code below for each unsupervised ML algorithm."]},{"cell_type":"code","source":["# -----------------------------------------------------------------------------------------------\n","# Comment and uncomment out the following unsupervised ML models to try them out.\n","unsupervised_model = PCA(n_components=2) # Feel free to change n_components, but try n_components=2 first.\n","#unsupervised_model = Isomap(n_components=2) # Feel free to change n_components, but try n_components=2 first.\n","#unsupervised_model = TSNE(random_state=42) # We dont need to set ``random_state`` to 42, this will just allow us to compare results between people for teaching purposes.\n","# -----------------------------------------------------------------------------------------------\n","\n","# use fit_transform instead of fit, as TSNE and Isomap has no transform method.\n","reduced_dimension_data = unsupervised_model.fit_transform(digits.data)\n","\n","# Separate your data into a training set (70 %) and a testing set (30 %).\n","Xtrain, Xtest, ytrain, ytest, indices_train, indices_test = train_test_split(reduced_dimension_data, digits.target, range(len(digits.target)), train_size=0.7, random_state=69)\n","\n","# Initialise the support vector classification algorithm in python.\n","#ml_algorithm = KNeighborsClassifier(n_neighbors=5)\n","ml_algorithm = SVC(C=100)\n","\n","# Train our dataset with the traning dataset that has been modified by the PCA algorithm.\n","ml_algorithm.fit(Xtrain, ytrain)\n","\n","# Make predictions for our testing dataset.\n","ypred = ml_algorithm.predict(Xtest)\n","\n","# Compare the results from our predictions with what the number actually is.\n","print('accuracy score: '+str(accuracy_score(ytest, ypred)))\n","print()\n","\n","# Create a spreadsheet showing the results of the confusion matrix.\n","overall_df = pd.DataFrame(\n","    df.values,\n","    pd.MultiIndex.from_product([['Actual Numbers'], df.index]),\n","    pd.MultiIndex.from_product([['Predicted Numbers'], df.columns])\n",")\n","overall_df.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\n","#display(overall_df)\n","\n","# Showing the results of the confusion matrix with colours. The darker the colour, the greater the number.\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","labels = sorted(set(ytest.tolist() + ypred.tolist()))\n","cm = confusion_matrix(ytest, ypred, labels=labels)\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n","\n","disp.plot(cmap='Blues')\n","plt.grid(False)\n","plt.ylabel('Actual Number')\n","plt.xlabel('Predicted Number')\n","plt.yticks(range(10))\n","plt.xticks(range(10))\n","ax = plt.gca()\n","ax.xaxis.tick_top()\n","ax.xaxis.set_label_position('top')\n","plt.show()"],"metadata":{"id":"HeQMt3F5jm-J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["You can also look at how your ML model is classifying each digit."],"metadata":{"id":"81vSbynAkD4m"}},{"cell_type":"code","source":["fig, axes = plt.subplots(10, 10, figsize=(8, 8))\n","fig.subplots_adjust(hspace=0.1, wspace=0.1)\n","\n","for i, ax in enumerate(axes.flat):\n","    ax.imshow(digits.images[indices_test[i]], cmap='binary')\n","    ax.text(0.05, 0.05, str(ypred[i]),\n","            transform=ax.transAxes,\n","            color='green' if (ytest[i] == ypred[i]) else 'red')\n","    ax.set_xticks([])\n","    ax.set_yticks([])\n","fig.show()"],"metadata":{"id":"CBZW80H3kDam"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**EXTRA IF YOU FINISH EARLY**: Repeat what we have just done using the kNN algorithm below. Try editting the code below to achieve this"],"metadata":{"id":"HlASL9OGPOVi"}},{"cell_type":"code","source":["# -----------------------------------------------------------------------------------------------\n","# Comment and uncomment out the following unsupervised ML models to try them out.\n","unsupervised_model = PCA(n_components=2)\n","#unsupervised_model = Isomap(n_components=2)\n","#unsupervised_model = TSNE(random_state=42) # We dont need to set ``random_state`` to 42, this will just allow us to compare results between people for teaching purposes.\n","# -----------------------------------------------------------------------------------------------\n","\n","# use fit_transform instead of fit, as TSNE and Isomap has no transform method.\n","reduced_dimension_data = unsupervised_model.fit_transform(digits.data)\n","\n","# Separate your data into a training set (70 %) and a testing set (30 %).\n","Xtrain, Xtest, ytrain, ytest, indices_train, indices_test = train_test_split(reduced_dimension_data, digits.target, range(len(digits.target)), train_size=0.7, random_state=69)\n","\n","# Initialise the kNN algorithm in python (Add your code in here).\n","\n","\n","# Train our dataset with the traning dataset that has been modified by the PCA algorithm (Add your code in here).\n","\n","\n","# Make predictions for our testing dataset (Add your code in here).\n","\n","\n","# Compare the results from our predictions with what the number actually is.\n","print('accuracy score: '+str(accuracy_score(ytest, ypred)))\n","print()\n","\n","# Create a spreadsheet showing the results of the confusion matrix.\n","overall_df = pd.DataFrame(\n","    df.values,\n","    pd.MultiIndex.from_product([['Actual Numbers'], df.index]),\n","    pd.MultiIndex.from_product([['Predicted Numbers'], df.columns])\n",")\n","overall_df.style.set_table_styles([dict(selector='th', props=[('text-align', 'center')])])\n","#display(overall_df)\n","\n","# Showing the results of the confusion matrix with colours. The darker the colour, the greater the number.\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","labels = sorted(set(ytest.tolist() + ypred.tolist()))\n","cm = confusion_matrix(ytest, ypred, labels=labels)\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n","\n","disp.plot(cmap='Blues')\n","plt.grid(False)\n","plt.ylabel('Actual Number')\n","plt.xlabel('Predicted Number')\n","plt.yticks(range(10))\n","plt.xticks(range(10))\n","ax = plt.gca()\n","ax.xaxis.tick_top()\n","ax.xaxis.set_label_position('top')\n","plt.show()"],"metadata":{"id":"KiZvfyH1PgKy"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}