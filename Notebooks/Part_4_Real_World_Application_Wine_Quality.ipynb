{"cells":[{"cell_type":"markdown","metadata":{"id":"amvHOkoFw8Dv"},"source":["# **Part 4: Apply What We Have Learnt on Real-World Data**\n","\n","During this tutorial we have learnt about supervised and unsupervised machine learning, and learnt about ome examples of these, including the k-nearest neighbour and the principal component analysis algorithms.\n","\n","In the last part of this tutorial, we will apply these techniques to a real-world data relating to testing the quality of red and white wine. Here, various information about the wine is recorded, such as acidity, concentrations of critic acid, sugars, and other, sulphates, alcohol percentage, and the overall quality of the wine.\n","\n","There are several goals for this part of the tutorial:\n","\n","* **Descriptors**: It is important to think about what descriptors will be useful for describing the problems you are trying to solve with machine learning. Many descriptors have been given, maybe some are more useful that others, maybe some are not important (I actually dont know).\n","* **Reuse your code**: It most cases, the easiest way to solve a programming problem is to take code you have already written and mold it so you can use the same code for different tasks. **Look at the code you have use in Part 2 and 3, and copy and paste the code from these that you find useful for achieve your objectives in these Part 4 examples.**\n","* **What do I do if I cant do something? Google it!**: Knowing how to use google to figure out how to do some programming task is crucial for doing any programming. When you face a problem you dont know how to solve, **try to use google to figure out how to solve your problem**. This is particularly useful with using the Scikit machine learning program in python\n","* **Read the Documentation**: Sometimes it is useful to read the documentation about how making plots in python works, or what variables a machine learning algorithm in scikit-learn can use. For example, here is the documentation for the k-nearest neighbour algorithm in scikit-learn: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html. This documentation may help you to solve programming problems.\n","* **Play**: A really reaaaaaaally important part of data science and programming in general is to play around with your data and dont be afraid to break things in order to learn something new about your dataset or the python programs you use, just make a backup copy of your work just in case you need to revert back to an early version of your code. In particular, see what you can do in Sckit-Learn: https://scikit-learn.org/stable/\n","\n","Think about these goals when you are writing machine learning code for these applications."]},{"cell_type":"markdown","source":["## **Preamble: Download the Packages for Running the Code**\n","\n","Run the code below to download the packages and files needed for this part of the tutorial."],"metadata":{"id":"NVEoCRb8-9Sp"}},{"cell_type":"code","source":["# Numpy and Pandas modules.\n","import numpy as np\n","import pandas as pd\n","\n","# Plotly and Matplotlib for plotting.\n","import pylab as pl\n","import plotly\n","import plotly.express as px\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","plt.style.use('seaborn')\n","\n","# Download and install packages that will be helpful for this section.\n","%pip install -q ipywidgets\n","!apt-get -qq install subversion\n","!svn checkout https://github.com/geoffreyweal/MESA_Bootcamp_ML_Tutorial/trunk/Notebooks/real_world_files\n","\n","# Clear the output just for this cell cause there is a lot going on and doesnt help us.\n","# Comment this out if there is a problem when loading the programs and packages above\n","from IPython.display import clear_output\n","clear_output()"],"metadata":{"id":"4v4HmTEW-9pI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kG7Cwhk09z3K"},"source":["## **Step 1: Get the Data**\n","\n","Run the code below to extract the data from the ``winequality-red.csv`` and ``winequality-white.csv`` files:"]},{"cell_type":"code","source":["red_wine_data = pd.read_csv(\"real_world_files/winequality-red.csv\",delimiter=';')\n","white_wine_data = pd.read_csv(\"real_world_files/winequality-white.csv\",delimiter=';')"],"metadata":{"id":"36HVVmZe4k21"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vj3OiMwD9z3M"},"source":["You can see the data that has been recorded for red and white wine below:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VwLppvGz9z3N"},"outputs":[],"source":["print('Red Wine Data')\n","print('Number of data points: '+str(len(red_wine_data)))\n","print()\n","display(red_wine_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vU9Zbtvj9z3O"},"outputs":[],"source":["print('White Wine Data')\n","print('Number of data points: '+str(len(white_wine_data)))\n","print()\n","display(white_wine_data)"]},{"cell_type":"markdown","source":["## **Step 2: Analysing/Visualising the Raw Data**\n","\n","It is useful to visualize the data in various ways, just to see what the ranges of the data are and what it contains."],"metadata":{"id":"KWeKTJ0G5Y3M"}},{"cell_type":"code","source":["red_wine_data.hist(bins=50,figsize=(10,10))\n","# display histogram\n","plt.show()"],"metadata":{"id":"rLapvZzA5ZMq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hBWdT3Tb9z3O"},"source":["## **Step 3: ML example with K-Nearest Neighbours Classification Algorithm**\n","\n","The aim is to create a machine learning model that can predict what features make a high quality wine.\n","\n","To begin, we need to move our data into a form where for the feature vectors:\n","\n","* Rows are the entries for each wine sampled\n","* Columns are all the different feature of the wine (feature vectors)."]},{"cell_type":"code","source":["# Convert our pandas data into a numpy array\n","red_wine_value_data = np.array(red_wine_data)\n","\n","# Collect the X data for our wine data, where:\n","#   - Rows are the entries for each wine sampled\n","#   - Columns are all the different feature of the wine (feature vectors).\n","X_red_wine = np.array(red_wine_value_data)[:, :-1]\n","print('X_red_wine shape: '+str(X_red_wine.shape))\n","\n","# Set the quality of the wine as our labels.\n","y_red_wine = np.array(red_wine_value_data)[:, -1]\n","print('X_red_wine shape: '+str(y_red_wine.shape))"],"metadata":{"id":"B_4upmufNb_U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Second, if you want to include an unsupervised machine learning algorithm, we can do this at this step in the process:"],"metadata":{"id":"gVejXCbZ1FUL"}},{"cell_type":"code","source":["# Initialise the PCA algorithm that will spread the data into 3 dimensions.\n","from sklearn.decomposition import PCA\n","from sklearn.manifold import Isomap\n","from sklearn.manifold import TSNE\n","\n","# -----------------------------------------------------------------------------------------------\n","# Comment and uncomment out the following unsupervised ML models to try them out.\n","unsupervised_model = PCA(n_components=3)\n","#unsupervised_model = Isomap(n_components=3)\n","#unsupervised_model = TSNE(n_components=3,random_state=42) # We dont need to set ``random_state`` to 42, this will just allow us to compare results between people for teaching purposes.\n","# -----------------------------------------------------------------------------------------------\n","\n","# Perform the PCA algorithm upon our dataset.\n","#_red_wine = unsupervised_model.fit_transform(X_red_wine)"],"metadata":{"id":"w6lk6wRz1E6N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can look at the data to see how complex it is (however, the best we can do is with a 3D plot):"],"metadata":{"id":"mZlLji8l1joC"}},{"cell_type":"code","source":["'''\n","# Show the dataset that has been spread out with the PCA algorithm in 3 dimensions\n","# with a 3D scatterplot.\n","data = np.concatenate((X_red_wine, np.atleast_2d(y_red_wine).T), axis=1)\n","df = pd.DataFrame(data, columns=['Feature 1', 'Feature 2', 'Feature 3', 'Quality'])\n","fig = px.scatter_3d(df, x='Feature 1', y='Feature 2', z='Feature 3', color='Quality', color_continuous_scale=plotly.colors.sequential.Rainbow, width=1000, height=800)\n","#fig.update_layout(showlegend=False)\n","fig.show()\n","'''"],"metadata":{"id":"-NHbxDmY1j97"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We then want to split our data into a training and testing set:"],"metadata":{"id":"dJTLcp62Q0wG"}},{"cell_type":"code","source":["# Split the data into training and testing data.\n","from sklearn.model_selection import train_test_split\n","X_red_wine_train, X_red_wine_test, y_red_wine_train, y_red_wine_test = train_test_split(X_red_wine, y_red_wine, stratify=y_red_wine, train_size=0.7, random_state=42)\n","\n","print('-----------------------------')\n","print('X_red_wine_train = '+str(X_red_wine_train.shape))\n","print('y_red_wine_train = '+str(y_red_wine_train.shape))\n","print('-----------------------------')\n","print('X_red_wine_test  = '+str(X_red_wine_test.shape))\n","print('y_red_wine_test  = '+str(y_red_wine_test.shape))\n","print('-----------------------------')"],"metadata":{"id":"hnHYu0FCQ7Zm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can now perform our kNN Classification Model on our red wine data, where we change the number of neighbours to see what is the best bersion"],"metadata":{"id":"0oHyPbovQnSK"}},{"cell_type":"code","source":["# First, let load the K-Nearest Neighbours Regression Model\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","# Testing KNN algorithm for several values of ``n_neighbors``.\n","training_accuracy = []\n","test_accuracy = []\n","neighbors_settings = tuple(range(1, 10))\n","for n_neighbors in neighbors_settings:\n","    # Build the model.\n","    ml_algorithm = KNeighborsClassifier(n_neighbors=n_neighbors)\n","    ml_algorithm.fit(X_red_wine_train, y_red_wine_train)\n","    # Record training set accuracy.\n","    training_accuracy.append(ml_algorithm.score(X_red_wine_train, y_red_wine_train))\n","    # Record generalization accuracy.\n","    test_accuracy.append(ml_algorithm.score(X_red_wine_test, y_red_wine_test))\n","\n","# Plot results for several values of ``n_neighbors``.\n","pl.plot(neighbors_settings, training_accuracy, '-', label=\"training accuracy\")\n","pl.plot(neighbors_settings, test_accuracy, 'r--', label=\"test accuracy\")\n","pl.ylabel(\"Accuracy\")\n","pl.xlabel(\"n_neighbors\")\n","pl.ylim((0.0,1.0))\n","pl.legend()\n","pl.show()"],"metadata":{"id":"a4uVYjOgQmH4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can also look at the confusion matrix to determine what quality values are being correctly and incorrectly identified for the various values of ``n_neighbors`` (note: the confusion matrix can only used for classification algorithms, at least easily)."],"metadata":{"id":"p3lIvIEYFUsn"}},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","\n","# Try changing this value and see what happens to the confusion matrix\n","n_neighbors = 1\n","\n","# Build the model.\n","ml_algorithm = KNeighborsClassifier(n_neighbors=n_neighbors)\n","ml_algorithm.fit(X_red_wine_train, y_red_wine_train)\n","# Record generalization accuracy.\n","y_red_wine_test_predictions = ml_algorithm.predict(X_red_wine_test)\n","\n","# Showing the results of the confusion matrix with colours. The darker the colour, the greater the number.\n","labels = sorted(set(y_red_wine_test.tolist() + y_red_wine_test_predictions.tolist()))\n","cm = confusion_matrix(y_red_wine_test, y_red_wine_test_predictions, labels=labels)\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n","\n","disp.plot(cmap='Blues')\n","plt.grid(False)\n","plt.ylabel('Actual Quaility')\n","plt.xlabel('Predicted Quaility')\n","plt.yticks(ticks=range(len(labels)),labels=labels)\n","plt.xticks(ticks=range(len(labels)),labels=labels)\n","ax = plt.gca()\n","ax.xaxis.tick_top()\n","ax.xaxis.set_label_position('top')\n","plt.show()"],"metadata":{"id":"nWgP4JBQFVBg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can also get scikit learn to give a more detailed report of how well our kNN algorithm worked. This can often help to figure out what type of wine quality data is being predicted correctly or not.\n","\n","The metrics given are:\n","\n","* **Precision**: Percentage of correct positive predictions relative to total positive predictions.\n","* **Recall**: Percentage of correct positive predictions relative to total actual positives.\n","* **F1-Score**: A weighted harmonic mean of precision and recall. The closer to 1, the better the model:\n","  * F1 Score $= \\frac{2 * (Precision * Recall)}{(Precision + Recall)}$\n","* **Support**: The number of actual occurrences of the class in the specified dataset"],"metadata":{"id":"RQkArisfQnqy"}},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","report = classification_report(y_red_wine_test, y_red_wine_test_predictions)\n","print(report)"],"metadata":{"id":"2NhIVNxEQvC3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Step 4: Wanna play with a Neural Network**\n","\n","We can also apply our data to a neutral network classification algorithm without doing to much to our original code. All we need to do is to change ``KNeighborsClassifier`` to ``MLPClassifier``"],"metadata":{"id":"Iu8yTAgLKOIp"}},{"cell_type":"code","source":["# ------------------------------------------------------------------------\n","# Reload the red and the white wine data.\n","red_wine_data = pd.read_csv(\"real_world_files/winequality-red.csv\",delimiter=';')\n","white_wine_data = pd.read_csv(\"real_world_files/winequality-white.csv\",delimiter=';')\n","\n","# ------------------------------------------------------------------------\n","# Convert our pandas data into a numpy array\n","red_wine_value_data = np.array(red_wine_data)\n","\n","# Collect the X data for our wine data, where:\n","#   - Rows are the entries for each wine sampled\n","#   - Columns are all the different feature of the wine (feature vectors).\n","X_red_wine = np.array(red_wine_value_data)[:, :-1]\n","print('X_red_wine shape: '+str(X_red_wine.shape))\n","\n","# Set the quality of the wine as our labels.\n","y_red_wine = np.array(red_wine_value_data)[:, -1]\n","print('X_red_wine shape: '+str(y_red_wine.shape))\n","\n","# ------------------------------------------------------------------------\n","# Split the data into training and testing data.\n","from sklearn.model_selection import train_test_split\n","X_red_wine_train, X_red_wine_test, y_red_wine_train, y_red_wine_test = train_test_split(X_red_wine, y_red_wine, stratify=y_red_wine, train_size=0.7, random_state=42)\n","\n","# ------------------------------------------------------------------------\n","# Apply a Neural Network to our wine data\n","from sklearn.neural_network import MLPClassifier\n","\n","# Apply our neural network settings list, where each number in the list are the number of neurons i each hidden layer.\n","# For example, (200,100) means there are 200 neurons in the first layer and 100 neuron in the second layer.\n","hidden_layer_sizes = (200,100)\n","\n","# Run and fit the NN algorithm\n","model = MLPClassifier(hidden_layer_sizes=(200,100), max_iter=1000)\n","model.fit(X_red_wine_train, y_red_wine_train)\n","\n","# ------------------------------------------------------------------------\n","# Obtain the predictions for our test set\n","y_red_wine_test_predictions = model.predict(X_red_wine_test)"],"metadata":{"id":"SkFniJ3KKTVd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can obtain the accuracy for our neural network at making predictions about the quality of our wine."],"metadata":{"id":"y1ZM3UjyQE13"}},{"cell_type":"code","source":["# Compare the results from our predictions with what the number actually is.\n","from sklearn.metrics import accuracy_score\n","print('accuracy score: '+str(accuracy_score(y_red_wine_test, y_red_wine_test_predictions)))"],"metadata":{"id":"81UWWx8UQFPO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can see what our neural network algorithm is doing well and not well with regards to wine quality predictions."],"metadata":{"id":"aSMzsdJ4LYZO"}},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n","\n","# Showing the results of the confusion matrix with colours. The darker the colour, the greater the number.\n","labels = sorted(set(y_red_wine_test.tolist() + y_red_wine_test_predictions.tolist()))\n","cm = confusion_matrix(y_red_wine_test, y_red_wine_test_predictions, labels=labels)\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n","disp.plot(cmap='Blues')\n","plt.grid(False)\n","plt.ylabel('Actual Quaility')\n","plt.xlabel('Predicted Quaility')\n","plt.yticks(ticks=range(len(labels)),labels=labels)\n","plt.xticks(ticks=range(len(labels)),labels=labels)\n","ax = plt.gca()\n","ax.xaxis.tick_top()\n","ax.xaxis.set_label_position('top')\n","plt.show()"],"metadata":{"id":"hmkw0t_LLYtI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can also get scikit learn to give a more detailed report of how well our neural network algorithm worked. This can often help to figure out what type of wine quality data is being predicted correctly or not.\n","\n","The metrics given are:\n","\n","* **Precision**: Percentage of correct positive predictions relative to total positive predictions.\n","* **Recall**: Percentage of correct positive predictions relative to total actual positives.\n","* **F1-Score**: A weighted harmonic mean of precision and recall. The closer to 1, the better the model:\n","  * F1 Score $= \\frac{2 * (Precision * Recall)}{(Precision + Recall)}$\n","* **Support**: The number of actual occurrences of the class in the specified dataset"],"metadata":{"id":"GZvtlyoFLZ6P"}},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","report = classification_report(y_red_wine_test, y_red_wine_test_predictions)\n","print(report)"],"metadata":{"id":"_niW484MLaNo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Step 5: Go nuts with the code**\n","\n","The aim is to create a machine learning model that can predict what features make a high quality wine.\n","\n","Have a good with trying out some other of these other methods:\n","\n","``[LinearRegression, SVR, KNeighborsRegressor, DecisionTreeRegressor, RandomForestRegressor, MLPRegressor, MinMaxScalar]``\n","\n","Take a look at the documentation on https://scikit-learn.org/stable/ on how to implement these algorithms. Copy the code above to help!"],"metadata":{"id":"IORt-wA3_xB_"}},{"cell_type":"code","source":["# Enter your code in here\n","\n"],"metadata":{"id":"XcwxWoucw4LF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Other Resources**\n","\n","Here are some resources to look at for this specific example:\n","\n","* https://rpubs.com/garrym3k/175762\n","* https://www.analyticsvidhya.com/blog/2021/04/wine-quality-prediction-using-machine-learning/\n","* https://medium.com/@chemistry8526/data-driven-wine-quality-analysis-exploring-red-and-white-wine-datasets-with-my-vivino-project-3b4618394549\n","* https://medium.com/analytics-vidhya/predicting-red-wine-quality-using-machine-learning-model-34e2b1b8d498"],"metadata":{"id":"qCVyIX0TVmUX"}}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}